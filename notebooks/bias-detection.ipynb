{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddaf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Path:\", sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup & data load ---\n",
    "import sys, platform, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy import stats\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Path:\", sys.executable)\n",
    "\n",
    "DATA_PATH = \"../data/sim_rater_dataset.csv\"  # adjust if needed\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "required = {\"item_id\",\"annotator_id\",\"label\",\"category\"}\n",
    "missing = required - set(df.columns)\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "print(\"Rows:\", len(df), \"| Items:\", df[\"item_id\"].nunique(), \"| Raters:\", df[\"annotator_id\"].nunique())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agreement metrics: pairwise Cohen's κ, Fleiss' κ, Krippendorff's α (nominal) ---\n",
    "# Pivot to items x raters matrix\n",
    "M = df.pivot_table(index=\"item_id\", columns=\"annotator_id\", values=\"label\", aggfunc=\"first\")\n",
    "raters = list(M.columns)\n",
    "\n",
    "# 1) Pairwise Cohen's κ\n",
    "pair_rows = []\n",
    "for a, b in itertools.combinations(raters, 2):\n",
    "    sub = M[[a,b]].dropna()\n",
    "    k = np.nan\n",
    "    if len(sub) > 0:\n",
    "        k = cohen_kappa_score(sub[a], sub[b])\n",
    "    pair_rows.append({\"rater_a\": a, \"rater_b\": b, \"cohen_kappa\": k, \"n_items\": len(sub)})\n",
    "pairwise = pd.DataFrame(pair_rows)\n",
    "mean_pairwise_kappa = pairwise[\"cohen_kappa\"].mean()\n",
    "\n",
    "# 2) Fleiss' κ (assumes each item has same # ratings; works reasonably with small variation)\n",
    "counts = df.groupby([\"item_id\",\"label\"]).size().unstack(fill_value=0).sort_index()\n",
    "N = counts.shape[0]\n",
    "n_per_item = counts.sum(axis=1).values\n",
    "if N == 0 or np.min(n_per_item) < 2:\n",
    "    fleiss_kappa = np.nan\n",
    "else:\n",
    "    # If items have varying #ratings, use the modal n to approximate P_i\n",
    "    n = int(pd.Series(n_per_item).mode().iloc[0])\n",
    "    # Re-normalize rows to 'n' by scaling (approx) if needed\n",
    "    scaled = counts.div(counts.sum(axis=1), axis=0).mul(n)\n",
    "    p_j = scaled.sum(axis=0).values / (N * n)\n",
    "    P_i = ((scaled**2).sum(axis=1) - n) / (n*(n-1))\n",
    "    P_bar = P_i.mean()\n",
    "    P_e = (p_j**2).sum()\n",
    "    fleiss_kappa = (P_bar - P_e) / (1 - P_e + 1e-12)\n",
    "\n",
    "# 3) Krippendorff's α (nominal)\n",
    "def kripp_alpha_nominal(matrix_items_by_raters: pd.DataFrame) -> float:\n",
    "    A = matrix_items_by_raters.values  # shape: items x raters\n",
    "    # map to 0/1 (or categories) and keep NaNs\n",
    "    cats = np.sort(pd.unique(matrix_items_by_raters.stack()))\n",
    "    # If no variation or too few labels:\n",
    "    if len(cats) == 0:\n",
    "        return np.nan\n",
    "    idx = {c:i for i,c in enumerate(cats)}\n",
    "    # coincidence matrix\n",
    "    C = np.zeros((len(cats), len(cats)), dtype=float)\n",
    "    for row in A:\n",
    "        vals = row[~pd.isna(row)]\n",
    "        if len(vals) < 2: \n",
    "            continue\n",
    "        # count pairwise coincidences\n",
    "        for i in range(len(vals)):\n",
    "            for j in range(len(vals)):\n",
    "                if i == j: \n",
    "                    continue\n",
    "                C[idx[vals[i]], idx[vals[j]]] += 1\n",
    "    Do = C.sum() - np.trace(C)\n",
    "    marg = C.sum(axis=0)\n",
    "    De = C.sum()**2 - (marg**2).sum()\n",
    "    if De <= 0:\n",
    "        return np.nan\n",
    "    return 1 - Do/De\n",
    "\n",
    "alpha = kripp_alpha_nominal(M)\n",
    "\n",
    "# --- Bias slices: label rate by category + chi-square ---\n",
    "label_of_interest = 1\n",
    "slice_rates = df.groupby(\"category\")[\"label\"].apply(lambda s: (s == label_of_interest).mean()).sort_values(ascending=False)\n",
    "\n",
    "ctab = pd.crosstab(df[\"category\"], df[\"label\"])\n",
    "if ctab.size > 0 and ctab.shape[0] > 1 and ctab.shape[1] > 1:\n",
    "    chi2, p, dof, exp = stats.chi2_contingency(ctab)\n",
    "else:\n",
    "    chi2, p, dof = (np.nan, np.nan, 0)\n",
    "\n",
    "# --- Print a clean summary ---\n",
    "print(\"\\n=== AGREEMENT ===\")\n",
    "print(f\"Mean pairwise Cohen's κ: {mean_pairwise_kappa:.3f}\")\n",
    "print(f\"Fleiss' κ:                {fleiss_kappa:.3f}\")\n",
    "print(f\"Krippendorff's α:         {alpha:.3f}\")\n",
    "\n",
    "print(\"\\n=== TOP PAIRWISE DISAGREEMENTS (lowest κ) ===\")\n",
    "display(pairwise.sort_values('cohen_kappa').head(5))\n",
    "\n",
    "print(\"\\n=== BIAS SLICES (label=1 rate by category) ===\")\n",
    "display(slice_rates.to_frame(\"label_rate\"))\n",
    "\n",
    "print(\"\\nChi-square across categories\")\n",
    "print(f\"χ²={chi2:.2f}, dof={dof}, p-value={p:.4g}\")\n",
    "\n",
    "# Optional: quick “so-what” hints you can read aloud\n",
    "print(\"\\n=== TAKEAWAYS (you can say this out loud) ===\")\n",
    "if not np.isnan(mean_pairwise_kappa):\n",
    "    if mean_pairwise_kappa < 0.4:\n",
    "        print(\"- Pairwise κ is low; raters may interpret guidelines inconsistently.\")\n",
    "    elif mean_pairwise_kappa < 0.6:\n",
    "        print(\"- Pairwise κ is moderate; check slices and recent guideline changes.\")\n",
    "    else:\n",
    "        print(\"- Pairwise κ is healthy overall; still review weak pairs/slices.\")\n",
    "if not np.isnan(fleiss_kappa) and fleiss_kappa < 0.6:\n",
    "    print(\"- Fleiss' κ below ~0.6 suggests multi-rater inconsistency worth triaging.\")\n",
    "if not np.isnan(alpha) and alpha < 0.6:\n",
    "    print(\"- Krippendorff's α < 0.6: reliability guardrail breach in messy, missing-label settings.\")\n",
    "if not np.isnan(p) and p < 0.05:\n",
    "    print(\"- Category label rates differ significantly (chi-square); investigate guideline clarity and rater mix for low-rate slices.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
